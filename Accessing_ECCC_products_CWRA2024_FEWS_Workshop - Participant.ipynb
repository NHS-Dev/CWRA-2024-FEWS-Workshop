{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCbtM3MjnL3e"
      },
      "source": [
        "# Exploring ECCC prediction products with the MSC's Geospatial Web Services"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "During this tutorial we'll explore the mechanics of retrieving prediction data from ECCC's Meteorological Service of Canada (MSC). We'll take a close look at three geospatial web services, the Web Map Service (WMS), the Web Coverage Service (WCS), and the Open Geospatial Consortium's (OGC) Features API. All three of these web services are application programming interfaces that allow us to \"talk with\" and receive data from the MSC's GeoMet service. In this tutorial we'll focus on retrieving precipitation analysis predictions and observed precipitation accumulations, but the \"recipes\" below apply to any datasets available from MSC's GeoMet. \n",
        "\n",
        "It's important to note that the code that we'll explore here is analagous to the code that your FEWS system uses to retreive data from the MSC. As such, the goals for this tutorial are to give you a sense of what is going on \"under the hood\" of your FEWS system and to familiarize you with the terminology and process of retrieving data from the MSC's geospatial web services. By the end of this tutorial you will understand how scripts can be used to retrieve images / data from the MSC and how these scripts can be used to manipulate raw prediction data to create maps and plots. Given that your FEWS system does the work of the code shown in this tutorial, it's not necessary to understand the minutae of the Python code blocks below. Rather, this tutorial is intended to provide you with general background information that you may find helpful when having technical discussions with your industry partners. The information in this tutorial may also prove useful for exploring MSC data further, and for the technically savvy, this tutorial can be a jumping off point for writing or contributing to related code.\n",
        "\n",
        "Finally, it's worth noting that your FEWS system likely fetches the majority of data from GeoMet's sister service, Datamart. Unfortunately, we won't explore Datamart during this tutorial for technical reasons (the data retrieval mechanism is hard to use in a \"lightweight\" tutorial like this, especially with conference centre WiFi!). However, the mechanics and process of querying for data from the two services is similar and the differences are not important for the purposes of this tutorial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4YKz7qwoQJT"
      },
      "source": [
        "## Setting things up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "78Fy5L5vnwrh"
      },
      "outputs": [],
      "source": [
        "# @title Downloading tutorial requirements into this Colab instance\n",
        "\n",
        "# The following `%%capture` command will hide a bunch of text that gets\n",
        "# generated when we install the following libraries\n",
        "%%capture\n",
        "!pip install owslib\n",
        "!pip install cartopy\n",
        "!pip install panel hvplot jupyter_bokeh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "pUTy2QYQlOBQ",
        "outputId": "38db97de-551b-4963-8b9d-2474ea1b8159"
      },
      "outputs": [],
      "source": [
        "# @title Setting up plotting environment\n",
        "import holoviews as hv\n",
        "import hvplot.pandas\n",
        "import panel as pn\n",
        "pn.extension()\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    def _render(self, **kw):\n",
        "        hv.extension('bokeh')\n",
        "        return hv.Store.render(self)\n",
        "    hv.core.Dimensioned._repr_mimebundle_ = _render"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cRGjLmi1rVOi"
      },
      "outputs": [],
      "source": [
        "# @title Importing tutorial requirements\n",
        "\n",
        "# Tools for handling data\n",
        "import re\n",
        "import warnings\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Tools that will help us connect to GeoMet's geospatial web services\n",
        "from owslib.wms import WebMapService\n",
        "from owslib.wcs import WebCoverageService\n",
        "from owslib.wcs import Authentication\n",
        "from owslib.ogcapi.features import Features\n",
        "from owslib.ogcapi.coverages import Coverages\n",
        "\n",
        "# Plotting tools\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib import cm\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from IPython.display import Image, display, clear_output\n",
        "import hvplot.xarray\n",
        "\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "# Here we'll set up a filter so we don't see a bunch of warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRyYQjJFpq00"
      },
      "source": [
        "In this tutorial we'll be viewing prediction data from the MSC's geospatial web services. This will involve making queries for data from a specific location in Canada. We'll define our location using a bounding box and we'll center our bounding box on a location of interest. You're welcome to center your bounding box on a location of your choosing, like your favourite gauge station, your office, your go-to camping spot, etc.\n",
        "\n",
        "To generate your bounding box, replace the values for the `lat` and `lon` variables below. To get the lat / lon coordinates of your place of interest, you can use this website: https://www.latlong.net/convert-address-to-lat-long.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg0xvBqzsEiz"
      },
      "outputs": [],
      "source": [
        "# @title Setting our location of interest\n",
        "\n",
        "# Lat / Lon coords for place of interest\n",
        "lat = \n",
        "lon = \n",
        "\n",
        "# We'll make our bounding box 5 x 5 degrees\n",
        "buffer = 5\n",
        "\n",
        "# Bounding box for the Web Map Service\n",
        "bbox_wms = (lon-buffer, lat-buffer*0.5, lon+buffer, lat+buffer*0.5)\n",
        "\n",
        "# Subset (bounding box) for the Web Coverage Service\n",
        "bbox_wcs = [('lat', lat-buffer, lat+buffer), ('lon', lon-buffer, lon+buffer)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH76BYBRow47"
      },
      "source": [
        "## Viewing current precipitation using GeoMet's Web Map Service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we'll start by creating an object, `wms` that will allow us to connect to GeoMet's web map service (WMS). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6mLDhZ1taz5"
      },
      "outputs": [],
      "source": [
        "# @title Creating a connection to the WMS\n",
        "\n",
        "# Create a connector object to query the Web Map Service\n",
        "wms = WebMapService(\n",
        "    f'https://geo.weather.gc.ca/geomet?&SERVICE=WMS',\n",
        "    version='1.3.0',\n",
        "    timeout=300\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll query for a map image from the High Resolution Determinisitic Precipitation Analysis (HRDPA). But before we can do that, we'll need to gather the information we need to construct our query. We can get this information from two places, 1) the WMS documentation and 2) our `wms` connection object. Starting with the WMS documentation we know we'll need the following info:\n",
        "\n",
        "- the name of the HRDPA layer\n",
        "- the style of the layer, or in other words, the colorbar for the map image\n",
        "- the format we'd like to receive the data in\n",
        "- the coordinate reference system that the data should be projected onto\n",
        "- the bounding box that the WMS will use to cut out the subset of the grid we're interested in\n",
        "\n",
        "From the documentation, we can see that to get a map image, we'll need to specify the data format as `image/jpeg` and we can use the default coordinate reference system, `EPSG:4326`. We defined our bounding box above, so that leaves the layer name and layer style for us to find. To get this information, we'll need to poke around with the `wms` connection object, or we can view the layer on AniMet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's explore the metadata with the `wms` connection object. First, we'll print all the available layers that contain the word `HRDPA`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI_VDAgwxFUR",
        "outputId": "95b71c27-c876-4f46-88ee-27e6d109ebfe"
      },
      "outputs": [],
      "source": [
        "# Print HRDPA layer names from the WMS connector\n",
        "for layer_name in wms.contents.keys():\n",
        "  if  in layer_name:\n",
        "    print(layer_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some of these layer names look a bit cryptic. We can choose to print a layer's title, which should give us a better indication of what the layer contains. For the first part of this tutorial, we'll explore the `HRDPA.6F_PR` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au_cg0vLymdB"
      },
      "outputs": [],
      "source": [
        "# The layer we're going to query in this section\n",
        "layer = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "XXi1JBdszX2d",
        "outputId": "2bcc6f9d-f0ba-47fe-d4de-e2cbdb36cc58"
      },
      "outputs": [],
      "source": [
        "# Check the layer title for additional detail\n",
        "wms[layer].title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's look for the available colourbars (layer styles) we can use for the map image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmNkSTFFz7I7",
        "outputId": "567a4b1a-6ac0-4f94-f730-3910622318ae"
      },
      "outputs": [],
      "source": [
        "# Check out the colourmap options for our layer\n",
        "for style, details in wms[layer].styles.items():\n",
        "  print(\n",
        "      f\"Style name: {style} \\n Link: {details['legend']}\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3loD87223E3"
      },
      "outputs": [],
      "source": [
        "# The default colourmap that we're going to specify for our layer\n",
        "hrdpa_style = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have the minimum information necessary to make a query. Let's make a query for a map image using the `wms` object and then we'll use Python's `Image` function to parse the information from the query and display the map. \n",
        "\n",
        "To get our requested information, the `wms` object takes our query parameters and formats them into a URL. The `wms` object URL tells GeoMet what information it should prepare for us. Then, the `wms` object requests the information that GeoMet prepared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "NeV63DP2tYIT",
        "outputId": "9e80848e-217e-436c-f630-7616b04b112c"
      },
      "outputs": [],
      "source": [
        "# @title Making a map query\n",
        "\n",
        "width = 500\n",
        "height = 250\n",
        "\n",
        "# Querying the WMS for a subset of our layer defined by our bounding box\n",
        "response = wms.getmap(\n",
        "    layers=[],\n",
        "    format='image/jpeg',\n",
        "    srs='EPSG:4326',\n",
        "    bbox=,\n",
        "    size=(width, height), # this defines the size of the map image\n",
        "    styles=[],\n",
        ")\n",
        "\n",
        "# Show image\n",
        "Image(response.read(), width=width, height=height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et voila! Precipitation accumulations should show up as colours on a black background. If you only see a black image, this is normal - it just means there isn't any accumulated precipitation in your bounding box for the timestep returned from the query (more on time in a moment...) \n",
        "\n",
        "Now that we've made our first query, let's have a look at the query URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "4gJPVLdTwPwr",
        "outputId": "12883197-0d07-4469-c322-0b393b21a5a9"
      },
      "outputs": [],
      "source": [
        "# The raw HTML for our WMS query\n",
        "response.geturl()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just like the `wms` object, your FEWS system would use an analogous process to construct URLS and query GeoMet. The code that we're playing around with here is similar to the code \"under the hood\" of your FEWS system.\n",
        "\n",
        "Let's explore some other aspects of making queries to GeoMet. Previously, we made a query for a map image with just the minimum amount of necessary information. Now you might be wondering what time the map image was issued. We can go back to our `wms` object to learn more about the time metadata for the HRDPA layer that we queried."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNDRh7AiGQ9z",
        "outputId": "dcb5ef40-375a-49b6-ee3b-155ca1c6f614"
      },
      "outputs": [],
      "source": [
        "# Pull out the time metadata\n",
        "time_info = wms[layer].dimensions['time']\n",
        "time_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the information about, we can first see a `default` time. When we don't specify any time information in our GeoMet queries, it will serve us the layer associated with the `default` time. The `default` time is typically the most recent forecast or analysis issue. Next, we can see several timestamps associated with the time `values`. This is a bit hard to read, so let's use Python to make this information more legible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cglS0w34Gw-5",
        "outputId": "77a5cc54-044d-45b7-dbb1-3ddd81ec1074"
      },
      "outputs": [],
      "source": [
        "# @title Exploring forecast issue and timestamp metadata\n",
        "\n",
        "start, end, issue_interval = time_info['values'][0].split('/')\n",
        "print(f\"First query-able time: {start}\")\n",
        "print(f\"End of query window: {end}\")\n",
        "print(f\"Interval that queries can be made: {issue_interval[-3:]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The time `values` reveal the window of time of currently available analyses for the HRDPA layer. In other words, we can query for analysis issues starting at the `start` time and make queries at six hour intervals until the `end` time. Note that the `default` time is the same as the `end` time. \n",
        "\n",
        "Now, let's make another map image query, but this time we'll specify an analysis issue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "YEHU-dU8HpPY",
        "outputId": "5fb7aef1-8cf0-48f8-cfc1-6666e5cd65c4"
      },
      "outputs": [],
      "source": [
        "width = 500\n",
        "height = 250\n",
        "\n",
        "# Querying the WMS for a subset of our layer defined by our bounding box\n",
        "response = wms.getmap(\n",
        "    layers=[layer],\n",
        "    format='image/jpeg',\n",
        "    srs='EPSG:4326',\n",
        "    bbox=bbox_wms,\n",
        "    size=(width, height),\n",
        "    styles=[hrdpa_style],\n",
        "    time=\n",
        ")\n",
        "\n",
        "# Show image\n",
        "Image(response.read(), width=width, height=height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And here is our new image! \n",
        "\n",
        "All this said, these images are a bit boring - we don't have any map features, or a colour bar. Making WMS queries like this with Python is a bit limited. But, if we query GeoMet for the raw data, instead of just a map image, we'll have much more freedom to create a custom map. Let's try this using GeoMet's Web Coverage Service (WCS)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYiPLRbVJ-X1"
      },
      "source": [
        "## Manipulating current precipitation using GeoMet's Web Coverage Service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just like we did above for the WMS, we'll start by creating an object, `wcs` that will allow us to connect to the WCS. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9BwHUntKTy1"
      },
      "outputs": [],
      "source": [
        "# @title Creating a connection to the WCS\n",
        "\n",
        "# Create a connector object to query the Web Map Service\n",
        "wcs = WebCoverageService(\n",
        "    f'https://geo.weather.gc.ca/geomet?&SERVICE=WCS&COVERAGEID',\n",
        "    version='2.0.1',\n",
        "    timeout=300\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fortunately, making WCS queries is very similar to making WMS queries. Let's try a query using the same parameters we specifed for our WMS queries. This time, we won't use the `Image` function to generate a map. Instead, we'll store the requested information in a dataset object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "A0jmlWXy5rVX",
        "outputId": "7a81c5de-2e40-4f1b-c2fd-5a96594ac592"
      },
      "outputs": [],
      "source": [
        "# @title Making a coverage query\n",
        "\n",
        "response = wcs.getCoverage(\n",
        "    identifier=[layer],\n",
        "    format='image/netcdf',\n",
        "    subsettingcrs='EPSG:4326', # note the small differences in parameter names between the WMS and WCS\n",
        "    subsets=bbox_wcs, # note the small differences in parameter names between the WMS and WCS \n",
        ")\n",
        "\n",
        "# Read data into a dataset object\n",
        "ds = xr.open_dataset(response.read()).load()\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's generate a custom plot. Note that by default the plotting code is hidden. For the purpose of this tutorial the details of the plotting code aren't important other than to know that we have much more flexibility to manipulate information from GeoMet if we grab the raw data. If you're curious you can use the arrow to the left of the code block to reveal the plotting code. \n",
        "\n",
        "And again, just like the code here, your FEWS system fetches raw data from the MSC servers and uses code to create custom visuals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "Xghyqduj5P1Z",
        "outputId": "6d459520-152f-4da0-8fc8-e53850c61e66"
      },
      "outputs": [],
      "source": [
        "#@title Plot: 6h precipitation amounts from HRDPA\n",
        "\n",
        "# Create custom colour-map for the HDRPA precip data\n",
        "min_precip = 0\n",
        "max_precip = 90\n",
        "interval = 30\n",
        "\n",
        "# more granularity for smaller precip accumulations\n",
        "lower_levels = [0.1, 0.5, 1, 2.5, 5, 10, 15, 20, 25]\n",
        "# less granularity for the larger precip accumulations\n",
        "upper_levels = list(range(30, max_precip+interval, interval))\n",
        "\n",
        "levels = lower_levels + upper_levels\n",
        "\n",
        "cmap = plt.get_cmap(\"turbo\").copy() # copy an existing color-map\n",
        "cmap.set_over(\"maroon\") # set the colour for the maximum level\n",
        "cmap.set_under(\"beige\") # set the colour for the minimum level\n",
        "\n",
        "# Create figure box\n",
        "fig = plt.figure(figsize=(6,8))\n",
        "\n",
        "# Specify coordinate reference system that the data will be projected to\n",
        "projection = ccrs.LambertConformal()\n",
        "ax = plt.axes(projection=projection)\n",
        "\n",
        "west, south, east, north = bbox_wms\n",
        "ax.set_extent([west, east, south, north])\n",
        "\n",
        "# Add HRDPA data to map\n",
        "\n",
        "x = ds['Band1']['lon']\n",
        "y = ds['Band1']['lat']\n",
        "\n",
        "mesh = ax.pcolormesh(\n",
        "    x, y, ds['Band1'],\n",
        "    transform=ccrs.PlateCarree(),\n",
        "    cmap=cmap,\n",
        "    norm=mcolors.BoundaryNorm(levels, ncolors=256, extend='both'),\n",
        "    label='none',\n",
        "    shading='auto'\n",
        ")\n",
        "\n",
        "# Add geographic features to map\n",
        "\n",
        "edgecolor = 'dimgrey'\n",
        "linewidth = 0.5\n",
        "\n",
        "# Physical features\n",
        "ax.add_feature(cf.COASTLINE, edgecolor=edgecolor, linewidth=linewidth)\n",
        "ax.add_feature(cf.LAND, edgecolor=edgecolor, facecolor=\"beige\", linewidth=linewidth)\n",
        "rivers = cf.NaturalEarthFeature(\n",
        "    category='physical',\n",
        "    name='rivers_lake_centerlines',\n",
        "    scale='10m',\n",
        "    linewidth=0.5,\n",
        "    edgecolor=edgecolor,\n",
        "    facecolor='none',\n",
        ")\n",
        "ax.add_feature(rivers)\n",
        "ax.add_feature(cf.LAKES, facecolor='white', edgecolor=edgecolor, linewidth=linewidth)\n",
        "\n",
        "# Country borders\n",
        "countries = cf.NaturalEarthFeature(\n",
        "    category='cultural',\n",
        "    name='admin_0_countries_lakes',\n",
        "    scale='10m',\n",
        "    edgecolor=edgecolor,\n",
        "    facecolor='none',\n",
        "    linewidth=linewidth\n",
        ")\n",
        "ax.add_feature(countries)\n",
        "\n",
        "# Province and Territory borders\n",
        "borders = cf.NaturalEarthFeature(\n",
        "    category='cultural',\n",
        "    name='admin_1_states_provinces_lines',\n",
        "    scale='10m',\n",
        "    edgecolor=edgecolor,\n",
        "    facecolor='none'\n",
        ")\n",
        "ax.add_feature(borders, linestyle='dashed')\n",
        "\n",
        "# Add colorbar as separate axis and make it the right size\n",
        "cb = fig.colorbar(\n",
        "    mesh,\n",
        "    location='bottom',\n",
        "    shrink=1.0,\n",
        "    pad=0.025,\n",
        "    fraction=0.05,\n",
        "    aspect=30,\n",
        "    label='6-hr total precipitation (mm)'\n",
        ")\n",
        "# cax = fig.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])\n",
        "# cb.cax.set_yticklabels([\"{:.0f}\".format(i) if i >= 1 else \"{:.1f}\".format(i) for i in cb.get_ticks()])\n",
        "\n",
        "# Add a plot title\n",
        "ax.set_title(\n",
        "      f\"Latest HRDPA 6-hr precip amount [mm]\"\n",
        "  );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now our map image looks more interesting!\n",
        "\n",
        "Just like with our first WMS query, we didn't specify any time information so our map was created using the latest analysis issue. Let's take a look to see what a WCS query looks like when we specify the time information. First, we'll load our time metadata from the WMS again.\n",
        "\n",
        "**Note: the metadata and time information for a given GeoMet layer is only available from the WMS. If you want to only make WCS queries, you will still need to create a `wms` object to look for the necessary metadata and time information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xol0-7z7-k3",
        "outputId": "ed5dabc4-02b8-464b-ce93-63bfcda915aa"
      },
      "outputs": [],
      "source": [
        "# Recall that metadata (including time info) comes from the WMS:\n",
        "# time_info = wms[layer].dimensions['time']\n",
        "\n",
        "start, end, issue_interval = time_info['values'][0].split('/')\n",
        "print(f\"First query-able time: {start}\")\n",
        "print(f\"End of query window: {end}\")\n",
        "print(f\"Interval that queries can be made: {issue_interval[-3:]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rather than querying for a specific issue time and making the same static map image again, let's query for multiple issue times and create a map animation. First, we'll use the time `values` to construct a list of all available analysis issue times. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUJ3XBfVsbtA"
      },
      "outputs": [],
      "source": [
        "first_time = start\n",
        "last_time = end\n",
        "\n",
        "iso_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
        "\n",
        "# Convert date strings to datetime objects\n",
        "first = datetime.strptime(first_time, iso_format)\n",
        "last = datetime.strptime(last_time, iso_format)\n",
        "\n",
        "# Remove anything that isn't a number from the datetime interval (time between issues)\n",
        "intvl = int(re.sub(r'\\D', '', issue_interval))\n",
        "\n",
        "# Create a list of forecast datetimes\n",
        "hrs = [first]\n",
        "while first < last:\n",
        "  first = first + timedelta(hours=intvl)\n",
        "  hrs.append(first)\n",
        "\n",
        "# create a list of ISO formatted datetime strings\n",
        "analysis_hrs = [datetime.strftime(hr, iso_format) for hr in hrs if hr < last]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we'll step through our list of available issue times and make a query for each time. Note that we need to make separate queries to GeoMet for each issue time. In other words, we can't make a query to GeoMet to return multiple layers at once.\n",
        "\n",
        "Depending on our WiFi speed, this next code block may take a minute or two to run. Let's run the code block and pause for questions while we wait for our queries to finish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "collapsed": true,
        "id": "J_XAulwsKrLD",
        "outputId": "177de5f9-e0ce-4c9d-9572-f008d834f52f"
      },
      "outputs": [],
      "source": [
        "# @title Querying for multiple predictions\n",
        "arrys = []\n",
        "\n",
        "for i in range(len(analysis_hrs)):\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    display(f\"Querying for layer at time {analysis_hrs[i]}\")\n",
        "\n",
        "    response = wcs.getCoverage(\n",
        "        identifier=[layer],\n",
        "        format='image/netcdf',\n",
        "        subsettingcrs='EPSG:4326',\n",
        "        subsets=bbox_wcs,\n",
        "        TIME=\n",
        "    )\n",
        "\n",
        "    # read into an xarray\n",
        "    ds = xr.open_dataset(response.read()).load()\n",
        "\n",
        "    # add the time metadata as a new dimension and coordinate\n",
        "    da = ds.expand_dims(time=[datetime.strptime(analysis_hrs[i], iso_format)])\n",
        "\n",
        "    # append to list of xarrays\n",
        "    arrys.append(da)\n",
        "\n",
        "fcasts = xr.concat([ds for ds in arrys], dim='time')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we're ready to create our animation. Just like above, the details of this code are hidden for simplicity. This code might also take a few minutes to finish and in the interest of time, we'll only animate a few layers (issue times)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "hjv3o2tP-RF7",
        "outputId": "ccb3cbca-3576-48ae-b4c2-538373631828"
      },
      "outputs": [],
      "source": [
        "#@title Animation: 6h precipitation amounts from HRDPA\n",
        "# Create figure box\n",
        "gs = GridSpec(1, 2, width_ratios = [0.9, 0.05])\n",
        "fig = plt.figure(figsize = (7, 7))\n",
        "\n",
        "# fig.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
        "\n",
        "# Specify coordinate reference system that the data will be projected to\n",
        "projection = ccrs.LambertConformal()\n",
        "ax = fig.add_subplot(gs[0], projection=projection)\n",
        "cbar_ax = fig.add_subplot(gs[1])\n",
        "\n",
        "# shrink the colorbar so that it has the same height as the plot\n",
        "b = cbar_ax.get_position()\n",
        "new_h = b.height*0.75\n",
        "pad = (b.height-new_h)/2.\n",
        "new_y0 = b.y0 + pad\n",
        "new_y1 = b.y1 - pad\n",
        "b.y0 = new_y0\n",
        "b.y1 = new_y1\n",
        "cbar_ax.set_position(b)\n",
        "\n",
        "west, south, east, north = bbox_wms\n",
        "ax.set_extent([west, east, south, north])\n",
        "\n",
        "x = fcasts['Band1']['lon']\n",
        "y = fcasts['Band1']['lat']\n",
        "\n",
        "# Add geographic features to map\n",
        "\n",
        "edgecolor = 'dimgrey'\n",
        "\n",
        "# Physical features\n",
        "ax.add_feature(cf.COASTLINE, edgecolor=edgecolor)\n",
        "ax.add_feature(cf.LAND, edgecolor=edgecolor, facecolor=\"beige\")\n",
        "rivers = cf.NaturalEarthFeature(\n",
        "    category='physical',\n",
        "    name='rivers_lake_centerlines',\n",
        "    scale='10m',\n",
        "    linewidth=0.5,\n",
        "    edgecolor=edgecolor,\n",
        "    facecolor='none',\n",
        ")\n",
        "ax.add_feature(rivers)\n",
        "ax.add_feature(cf.LAKES, facecolor='white', edgecolor=edgecolor)\n",
        "\n",
        "# Country borders\n",
        "countries = cf.NaturalEarthFeature(\n",
        "    category='cultural',\n",
        "    name='admin_0_countries_lakes',\n",
        "    scale='10m',\n",
        "    edgecolor=edgecolor,\n",
        "    facecolor='none'\n",
        ")\n",
        "ax.add_feature(countries)\n",
        "\n",
        "# Province and Territory borders\n",
        "borders = cf.NaturalEarthFeature(\n",
        "    category='cultural',\n",
        "    name='admin_1_states_provinces_lines',\n",
        "    scale='10m',\n",
        "    edgecolor=edgecolor,\n",
        "    facecolor='none'\n",
        ")\n",
        "ax.add_feature(borders, linestyle='dashed')\n",
        "\n",
        "mesh = ax.pcolormesh(\n",
        "      x, y, fcasts['Band1'].sel(time=hrs[0]),\n",
        "      transform=ccrs.PlateCarree(),\n",
        "      cmap=cmap, norm=mcolors.BoundaryNorm(levels, ncolors=256, extend='both'),\n",
        "      label='none', shading='auto'\n",
        "  )\n",
        "cbar_ax.set_yticklabels([\"{:.0f}\".format(i) if i >= 1 else \"{:.1f}\".format(i) for i in cb.get_ticks()])\n",
        "fig.colorbar(mesh, cax=cbar_ax, ticks=levels, label='6-hr total precipitation (mm)')\n",
        "\n",
        "\n",
        "def update_map(i):\n",
        "  mesh = ax.pcolormesh(\n",
        "      x, y, fcasts['Band1'].sel(time=hrs[i]),\n",
        "      transform=ccrs.PlateCarree(),\n",
        "      cmap=cmap, norm=mcolors.BoundaryNorm(levels, ncolors=256, extend='both'),\n",
        "      label='none', shading='auto'\n",
        "  )\n",
        "  ax.set_title(\n",
        "      f\"HRDPA 6-hr precip amount [mm] valid for {analysis_hrs[i]} UTC\"\n",
        "  )\n",
        "\n",
        "anim = FuncAnimation(fig, update_map, frames=8, interval=600, repeat=False)\n",
        "plt.close()\n",
        "anim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And there you have it! We've finished running through the basics of the WMS and WCS APIs. We've seen how we can use the WMS to retrieve metadata and generate simple map images to give us a \"first look\" at GeoMet layers. And we've seen how we can manipulate and customize info from GeoMet by retrieving the raw data from the WCS. We've also learned that the code here is analogous to the functionality of your FEWS system that retrieves data from the MSC. \n",
        "\n",
        "To round out this tutorial, we'll have a quick look at GeoMet's newer APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwmx6csgkaCV"
      },
      "source": [
        "## Viewing forecasted precipitation using GeoMet's OGC-Features API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Web Map and Web Coverage services are GeoMet's mature geospatial web services, but more recently, GeoMet has offered data from a suite of newer services, the OGC APIs. In this tutorial, we'll explore the OGC-Features API. The goal for this next section will be to compare the HRDPA precipitation amounts we retrieved from the WCS earlier with observed precipitation amounts from a climate station close to the location of interest that we specified at the beginning of this tutorial. We'll use the OGC-Features API to grab the precipiation observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If your original location didn't have much going on in terms of precipitation, you can change the coordinates in the box below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mu7XNJmkmYZ"
      },
      "outputs": [],
      "source": [
        "# Lat / Lon coords for place of interest\n",
        "lat = 45.48\n",
        "lon = -73.79\n",
        "\n",
        "buffer = 1.0\n",
        "\n",
        "# Bounding box for the Web Map Service\n",
        "bbox_oafeat = (lon-buffer, lat-buffer*0.5, lon+buffer, lat+buffer*0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To start let's create a OGC-Features API connection, which we'll call `oafeat`. Next, we'll make two queries. First, we'll query the collection of climate stations to find a station that has real-time data. Then, we'll use the climate station ID to request data from the station. Unlike, the WMS and WCS, both the metadata and data are available via the OGC-Features API. Another bonus of the OGC-Features API is that we can preview the available data and explore its metadata in our browser. This makes it easier to find the query information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gccBwdsQROyI"
      },
      "outputs": [],
      "source": [
        "# @title Creating a connection to the OGC-Features API and making a query\n",
        "\n",
        "oafeat = Features(\"https://api.weather.gc.ca/\")\n",
        "\n",
        "# Make a query for climate station metadata\n",
        "stations = oafeat.collection_items(\n",
        "    'climate-stations', # here we're specifying that we'll query the collection of climate stations\n",
        "    bbox=bbox_oafeat,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's store the information from the Features API in a table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "2xHMJlEwol94",
        "outputId": "83a8b1d3-91a9-441f-c2b8-8dc1101cde29"
      },
      "outputs": [],
      "source": [
        "station_table = gpd.GeoDataFrame.from_features(stations['features'])\n",
        "station_table.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the information from the table above, pick a station with real-time data and enter its station ID into the code block below as the variable `stn_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqO_Y807pMmz"
      },
      "outputs": [],
      "source": [
        "stn_id = \n",
        "\n",
        "# We'll grab data as far back as the first available analysis time until the latest available time\n",
        "start = start \n",
        "end = station_table['HLY_LAST_DATE'].loc[station_table['STN_ID'] == stn_id]\n",
        "\n",
        "# Filter the table so that we remove all unneeded stations\n",
        "stn = station_table.loc[station_table['STN_ID'] == stn_id]\n",
        "\n",
        "# Pull out the station latitude and longitude\n",
        "stn_lon = stn['geometry'].x.values[0]\n",
        "stn_lat = stn['geometry'].y.values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "RD6X65okqDmw",
        "outputId": "2079ec8e-057a-4957-d802-cdf958811a46"
      },
      "outputs": [],
      "source": [
        "# Make a query for data from a climate station\n",
        "weather = oafeat.collection_items(\n",
        "    \n",
        "    bbox=\n",
        "    STN_ID= # we'll filter our query by our station of interest\n",
        "    datetime=f\"{start}/{end}\" # and we'll filter by our specified time period\n",
        ")\n",
        "# again, we'll store this information in a table\n",
        "weather_table = gpd.GeoDataFrame.from_features(weather['features'])\n",
        "weather_table.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABSzd0qTrfVX",
        "outputId": "7f6ef0b7-571c-4789-c7dd-76ab22001392"
      },
      "outputs": [],
      "source": [
        "# Sanity check that this station is recording precipitation\n",
        "weather_table['PRECIP_AMOUNT'].sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we've fetched our precipitation observations, we'll clean up our data table to make manipulating and plotting the data easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8DCqRHr0CRb"
      },
      "outputs": [],
      "source": [
        "# Remove all columns aside from the time and precip amount\n",
        "precip = weather_table[['UTC_DATE', 'PRECIP_AMOUNT']]\n",
        "\n",
        "# Rename the columns for nice plot titles\n",
        "precip = precip.rename(columns={'UTC_DATE': 'Time', 'PRECIP_AMOUNT': 'Observations'})\n",
        "\n",
        "# Index our table by time so that we can put our data in the proper order\n",
        "precip = precip.set_index('Time')\n",
        "precip.index = pd.to_datetime(precip.index)\n",
        "precip.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we want to compare the precipitation observations with the data from HRDPA, we will need to compute the observed 6-hr accumulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1VHJATV2kG8"
      },
      "outputs": [],
      "source": [
        "# Aggregate the hourly precipitation amounts over 6-hour intervals\n",
        "precip = precip.resample(rule='6H', closed='right', label='right').sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "7i83TDRjUwXu",
        "outputId": "ba1f7aeb-7b6b-4698-c4bb-d0937364da02"
      },
      "outputs": [],
      "source": [
        "# Print the stop of the precipitation table to take a peak at the data\n",
        "precip.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's query for the HRDPA data again from the WCS just in case the available times changed or if we changed our location of interest. Let's also query for data from the Regional Deterministic Precipitation Analysis (RDPA) to add to our comparison. Since we've seen this code above, we've hidden it here for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "McRpkTkVYUmj",
        "outputId": "46fdf536-1752-477f-e5a1-76958e081d30"
      },
      "outputs": [],
      "source": [
        "# @title Querying for model data for comparison\n",
        "buffer = 5\n",
        "bbox_wcs = [('lat', lat-buffer, lat+buffer), ('lon', lon-buffer, lon+buffer)]\n",
        "\n",
        "arrys = []\n",
        "\n",
        "for i in range(len(analysis_hrs)):\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    display(f\"Querying for HRDPA layer at time {analysis_hrs[i]}\")\n",
        "\n",
        "    response = wcs.getCoverage(\n",
        "        identifier=['HRDPA.6F_PR'],\n",
        "        format='image/netcdf',\n",
        "        subsettingcrs='EPSG:4326',\n",
        "        subsets=bbox_wcs,\n",
        "        TIME=analysis_hrs[i]\n",
        "    )\n",
        "\n",
        "    # read into an xarray\n",
        "    ds = xr.open_dataset(response.read()).load()\n",
        "\n",
        "    # add the time metadata as a new dimension and coordinate\n",
        "    da = ds.expand_dims(time=[datetime.strptime(analysis_hrs[i], iso_format)])\n",
        "\n",
        "    # append to list of xarrays\n",
        "    arrys.append(da)\n",
        "\n",
        "hrdpa_fcasts = xr.concat([ds for ds in arrys], dim='time')\n",
        "\n",
        "arrys = []\n",
        "\n",
        "for i in range(len(analysis_hrs)):\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    display(f\"Querying for RDPA layer at time {analysis_hrs[i]}\")\n",
        "\n",
        "    response = wcs.getCoverage(\n",
        "        identifier=['RDPA.6F_PR'],\n",
        "        format='image/netcdf',\n",
        "        subsettingcrs='EPSG:4326',\n",
        "        subsets=bbox_wcs,\n",
        "        TIME=analysis_hrs[i]\n",
        "    )\n",
        "\n",
        "    # read into an xarray\n",
        "    ds = xr.open_dataset(response.read()).load()\n",
        "\n",
        "    # add the time metadata as a new dimension and coordinate\n",
        "    da = ds.expand_dims(time=[datetime.strptime(analysis_hrs[i], iso_format)])\n",
        "\n",
        "    # append to list of xarrays\n",
        "    arrys.append(da)\n",
        "\n",
        "rdpa_fcasts = xr.concat([ds for ds in arrys], dim='time')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just like we cleaned up the observations, we'll also clean up the analysis data. Importantly, when we query a layer from GeoMet, it is returned to us with a generic name, `Band1`. We'll want to change the `Band1` name so we can differentiate the HRDPA and RDPA data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "A0B8VghET1Y5",
        "outputId": "b9ab3df0-7c11-4409-ebf3-b586074095c1"
      },
      "outputs": [],
      "source": [
        "# Select only the grid cell that contains or is closest to our climate station\n",
        "hrdpa = hrdpa_fcasts.sel(lat=stn_lat, lon=stn_lon, method='nearest')\n",
        "# Move the HRDPA data into a dataframe\n",
        "hrdpa = hrdpa.to_dataframe().drop(columns=['lat', 'lon', 'crs'])\n",
        "# Rename the `Band1` column to something more prescriptive\n",
        "hrdpa = hrdpa.rename(columns={'time': 'Time', 'Band1': 'HRDPA'})\n",
        "hrdpa.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "houeog8XaZGu",
        "outputId": "be56993c-a16e-4ed2-ed29-6d16648609c4"
      },
      "outputs": [],
      "source": [
        "# We'll do the same cleanup with the RDPA data\n",
        "rdpa = rdpa_fcasts.sel(lat=stn_lat, lon=stn_lon, method='nearest')\n",
        "rdpa = rdpa.to_dataframe().drop(columns=['lat', 'lon', 'crs'])\n",
        "rdpa = rdpa.rename(columns={'time': 'Time', 'Band1': 'RDPA'})\n",
        "rdpa.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that our data cleanup is finished, we can merge the observed and analysis data into one table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "V-R5655qVUKz",
        "outputId": "d3fde954-874c-4b2a-f2c7-0d98bcc4d71a"
      },
      "outputs": [],
      "source": [
        "# Combine the HRDPA, RDPA, and observed precip data into one table\n",
        "precip = precip.join(hrdpa)\n",
        "precip = precip.join(rdpa)\n",
        "precip.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also take the cumulative sum of the precipitation amounts over the whole period so that we can visualize the data in a couple of different ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9OuPmdgVuLm"
      },
      "outputs": [],
      "source": [
        "# Compute the cumulative precipitation amounts for each precip time series\n",
        "precip['Cumulative Observations'] = precip['Observations'].cumsum()\n",
        "precip['Cumulative HRDPA'] = precip['HRDPA'].cumsum()\n",
        "precip['Cumulative RDPA'] = precip['RDPA'].cumsum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's plot a time series of 6-hour precipitation amounts and let's create a small table to the right of the plot so we can explore the data values. How well does the prediction and observed data compare? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "ex87ZiRxWKN4",
        "outputId": "e5828941-5f39-4e53-948a-d26631bbca21"
      },
      "outputs": [],
      "source": [
        "(precip.hvplot.step(x='Time', y=['Observations', 'HRDPA', 'RDPA'], value_label='6-hr Precipitation amounts (mm)') +\n",
        " precip.hvplot.table(['Time', 'Observations', 'HRDPA', 'RDPA']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compare the observed data and prediction data in another way by looking at the cumulative amounts over the entire period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "KGRZFp4hXySt",
        "outputId": "c152f743-14dd-4944-eb12-31aea78cf7ba"
      },
      "outputs": [],
      "source": [
        "(precip.hvplot.step(x='Time', y=['Cumulative Observations', 'Cumulative HRDPA', 'Cumulative RDPA'], value_label='Cumulative precipitation (mm)') +\n",
        " precip.hvplot.table(['Time', 'Cumulative Observations', 'Cumulative HRDPA', 'Cumulative RDPA']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that's a wrap! In this section we learned how queries are made to the newer GeoMet API, OGC-Features. We saw that the mechanics of the queries were similar to the way we query the WMS and WCS, but that the Features API provides more convenient ways to explore the data and associated metadata. Note that hydrometric observations are available via GeoMet using the OGC-Features API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overall, this tutorial provides a brief technical overview of retrieving prediction data from the MSC's GeoMet. While the mechanics of querying for data from GeoMet appear straightforward here, we still need a fair amount of requisite knowledge and coding ability to make requests and manipulate the prediction information. A data management system like FEWS removes or lessens these technical requirements. Notwithstanding, tutorials like these can help FEWS users and others become generally familiar with the way data is retrieved from GeoMet and they can provide helpful background information for technical discussions with industry partners. Also, for FEWS users who would like a hand in managing or adding to their FEWS configuration, tutorials like these can provide a gentle introduction to the various GeoMet APIs and point users to associated documentation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
